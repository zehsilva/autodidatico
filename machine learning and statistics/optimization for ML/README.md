### Foundations
- [Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers. Boyd et al](https://www.uio.no/studier/emner/matnat/math/STK4051/v20/admm_distr_stats.pdf)
- [A Survey of Algorithms and Analysis for Adaptive Online Learning](https://www.jmlr.org/papers/volume18/14-428/14-428.pdf)
- [A Survey of Optimization Methods from a Machine Learning Perspective](https://arxiv.org/pdf/1906.06821.pdf)
- [An overview of gradient descent optimization algorithms (Ruder)](https://arxiv.org/pdf/1609.04747.pdf)
- [Stochastic Gradient Descent Tricks (Bottou)](https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/tricks-2012.pdf)
- [Convex Optimization: Algorithms and Complexity (Bubeck)](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/01/Bubeck15.pdf)
- [Integer Optimization Methods for Machine Learning](https://core.ac.uk/download/pdf/9342277.pdf)


### Research threads
- [Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian](https://papers.nips.cc/paper/2020/file/08425b881bcde94a383cd258cea331be-Paper.pdf)
- [Monte Carlo Gradient Estimation in Machine Learning](https://www.jmlr.org/papers/volume21/19-346/19-346.pdf)
